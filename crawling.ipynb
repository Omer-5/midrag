{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    " \n",
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all categories links and names\n",
    "def Categories_To_CSV():\n",
    "    driver.get(\"https://www.midrag.co.il/Content/MainFeedbacksIndex\")\n",
    "\n",
    "    categories = driver.find_elements(By.CLASS_NAME, \"sec-feedback-index\")\n",
    "    category_names = []\n",
    "    urls = []\n",
    "\n",
    "    for cat in categories:\n",
    "        curr = cat.find_element(By.TAG_NAME,\"a\")\n",
    "\n",
    "        #if curr.text in hot_categories:\n",
    "        category_names.append((curr.text))\n",
    "        urls.append(curr.get_attribute('href'))\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame({\"Category Name\": category_names, \"URL\": urls, \"Total Reivews\": -1, \"Is Relavent\": 0, \"Scanned\": 0})\n",
    "    Save_CSV(\"all_categories.csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update total reviews in CSV and sort accordingly\n",
    "def Update_Total_Reivews(df):\n",
    "    for index, url  in enumerate(df[\"URL\"]):\n",
    "        driver.get(url)\n",
    "\n",
    "        total_reviews_XPATH = '/html/body/div[1]/div[1]/div[3]/div[1]/div[4]/div/div[1]/h1'\n",
    "        total_reviews_raw = driver.find_elements(By.XPATH, total_reviews_XPATH)\n",
    "        total_reviews = 0\n",
    "        total_reviews = int(''.join(re.findall(r'\\b\\d+\\b', total_reviews_raw[0].text)))\n",
    "\n",
    "        df.iloc[index,3] = total_reviews\n",
    "    \n",
    "    df.sort_values(by=['Is Relevant', 'Scanned'],inplace=True, ascending=[False, False])\n",
    "    Save_CSV(\"all_categories.csv\", df)\n",
    "\n",
    "# df = pd.read_csv(\"data\\\\all_categories.csv\")\n",
    "# Update_Total_Reivews(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.midrag.co.il/Content/LttrInSec/1?lttr=%D7%94&lttrAsc=228', 'https://www.midrag.co.il/Content/LttrInSec/1?lttr=%D7%A4&lttrAsc=244']\n"
     ]
    }
   ],
   "source": [
    "# Extract All Sub-Categories to CSV\n",
    "def Get_All_Subcateogires_By_URL(cat_url):\n",
    "    driver.get(cat_url)\n",
    "    # Click on \"כל האותיות\" on page\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[3]/div[1]/div[4]/div/div[2]/a\").click()\n",
    "    # get all letters divs\n",
    "    all_letters_raw = driver.find_elements(By.CLASS_NAME,\"sec-feedback-index\")\n",
    "\n",
    "    all_letters_URL = []\n",
    "    for letter in all_letters_raw:\n",
    "        all_letters_URL.append(letter.find_element(By.TAG_NAME,'a').get_attribute('href'))\n",
    "\n",
    "    print(all_letters_URL)\n",
    "    # Call letter extractor for each link\n",
    "\n",
    "Get_All_Subcateogires_By_URL(\"https://www.midrag.co.il/Content/SecFeedbacksIndex/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Append_Or_Create_CSV_By_Name(CSV_name, df):\n",
    "    output_path=f'data/{CSV_name}'\n",
    "    df.to_csv(output_path, mode='a', index =False, header=not os.path.exists(output_path), encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Save_CSV(CSV_name, df):\n",
    "    df.to_csv(f\"data/{CSV_name}\", index=False, encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all reviews link from a letter URL and save those to CSV file\n",
    "def Extract_All_Sub_Categories_URLS_From_Letter_Page(letter_url):\n",
    "    driver.get(letter_url)\n",
    "\n",
    "    CSV_file_name = \"all_subcategories_URLs.csv\"\n",
    "    category_name = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[3]/div[1]/div[1]/div/ol/li[2]/a/span\").text\n",
    "    all_links_raw = driver.find_elements(By.CLASS_NAME,\"lttr-feedback-index\")\n",
    "\n",
    "    all_sub_link = []\n",
    "    all_sub_name = []\n",
    "    all_sub_count = []\n",
    "\n",
    "    for link in all_links_raw:\n",
    "        a_tag = link.find_element(By.TAG_NAME,'a')\n",
    "\n",
    "        all_sub_link.append(a_tag.get_attribute('href'))\n",
    "\n",
    "        sub_name = re.sub(r'\\([^)]*\\)', '', a_tag.text)\n",
    "        count = re.findall(r'\\d+', a_tag.text.replace(sub_name, \"\")).pop()\n",
    "        \n",
    "        all_sub_name.append(sub_name)\n",
    "        all_sub_count.append(count)\n",
    "        \n",
    "    df = pd.DataFrame({\"Category\": category_name, \"Subcategory\" : all_sub_name,\"Number Of Reviews\" : all_sub_count,\"Link\" : all_sub_link, \"scanned\" : 0})\n",
    "    Append_Or_Create_CSV_By_Name(CSV_file_name, df)\n",
    "\n",
    "Extract_All_Sub_Categories_URLS_From_Letter_Page(\"https://www.midrag.co.il/Content/LttrInSec/1?lttr=%D7%94&lttrAsc=228\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1bcf6aa5089fc5c5898a08ac643fd6d5eb64a5e1b049103d6b5e195c1f1aa1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
