{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from utils import Save_CSV, Append_Or_Create_CSV_By_Name\n",
    "  \n",
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all categories links and names\n",
    "def Categories_To_CSV():\n",
    "    driver.get(\"https://www.midrag.co.il/Content/MainFeedbacksIndex\")\n",
    "\n",
    "    categories = driver.find_elements(By.CLASS_NAME, \"sec-feedback-index\")\n",
    "    category_names = []\n",
    "    urls = []\n",
    "\n",
    "    for cat in categories:\n",
    "        curr = cat.find_element(By.TAG_NAME,\"a\")\n",
    "\n",
    "        #if curr.text in hot_categories:\n",
    "        category_names.append((curr.text))\n",
    "        urls.append(curr.get_attribute('href'))\n",
    "        \n",
    "\n",
    "    df = pd.DataFrame({\"Category Name\": category_names, \"URL\": urls, \"Total Reivews\": -1, \"Is Relavent\": 0, \"Scanned\": 0})\n",
    "    Save_CSV(\"all_categories.csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update total reviews in CSV and sort accordingly\n",
    "def Update_Total_Reviews(df:pd.DataFrame):\n",
    "    for index, url  in enumerate(df[\"URL\"]):\n",
    "        driver.get(url)\n",
    "\n",
    "        total_reviews_XPATH = '/html/body/div[1]/div[1]/div[3]/div[1]/div[4]/div/div[1]/h1'\n",
    "        total_reviews_raw = driver.find_elements(By.XPATH, total_reviews_XPATH)\n",
    "        total_reviews = 0\n",
    "        total_reviews = int(''.join(re.findall(r'\\b\\d+\\b', total_reviews_raw[0].text)))\n",
    "\n",
    "        df.iloc[index,3] = total_reviews\n",
    "    \n",
    "    df.sort_values(by=['Is Relevant', 'Scanned'],inplace=True, ascending=[False, False])\n",
    "    Save_CSV(\"all_categories.csv\", df)\n",
    "\n",
    "# Update_Total_Reviews(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract All Sub-Categories to CSV\n",
    "def Get_All_Subcategories_By_URL(cat_url):\n",
    "    driver.get(cat_url)\n",
    "    # Click on \"כל האותיות\" on page\n",
    "    driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[3]/div[1]/div[4]/div/div[2]/a\").click()\n",
    "    # get all letters divs\n",
    "    all_letters_raw = driver.find_elements(By.CLASS_NAME,\"sec-feedback-index\")\n",
    "\n",
    "    all_letters_URL = []\n",
    "    for letter in all_letters_raw:\n",
    "        all_letters_URL.append(letter.find_element(By.TAG_NAME,'a').get_attribute('href'))\n",
    "\n",
    "    # print(all_letters_URL)\n",
    "\n",
    "    df = pd.DataFrame({\"URL\":all_letters_URL, \"Scanned\": 0})\n",
    "    Append_Or_Create_CSV_By_Name(\"letters_URLs.csv\", df)\n",
    "\n",
    "# Get_All_Subcategories_By_URL(\"https://www.midrag.co.il/Content/SecFeedbacksIndex/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all reviews link from a letter URL and save those to CSV file\n",
    "def Extract_All_Sub_Categories_URLS_From_Letter_Page(letter_url):\n",
    "    driver.get(letter_url)\n",
    "\n",
    "    CSV_file_name = \"all_subcategories_URLs.csv\"\n",
    "    category_name = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[3]/div[1]/div[1]/ol/li[2]/a/span\").text\n",
    "    all_links_raw = driver.find_elements(By.CLASS_NAME,\"lttr-feedback-index\")\n",
    "\n",
    "    all_sub_link = []\n",
    "    all_sub_name = []\n",
    "    all_sub_count = []\n",
    "\n",
    "    for link in all_links_raw:\n",
    "        a_tag = link.find_element(By.TAG_NAME,'a')\n",
    "\n",
    "        all_sub_link.append(a_tag.get_attribute('href'))\n",
    "\n",
    "        sub_name = re.sub(r'\\([^)]*\\)', '', a_tag.text)\n",
    "        count = re.findall(r'\\d+', a_tag.text.replace(sub_name, \"\")).pop()\n",
    "        \n",
    "        all_sub_name.append(sub_name)\n",
    "        all_sub_count.append(count)\n",
    "        \n",
    "    df = pd.DataFrame({\"Category\": category_name, \"Subcategory\" : all_sub_name,\"Number Of Reviews\" : all_sub_count,\"Link\" : all_sub_link, \"Scanned\" : 0})\n",
    "    Append_Or_Create_CSV_By_Name(CSV_file_name, df)\n",
    "\n",
    "# Extract_All_Sub_Categories_URLS_From_Letter_Page(\"https://www.midrag.co.il/Content/LttrInSec/1?lttr=%D7%94&lttrAsc=228\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Loop_All_Letter_Page(base_url):\n",
    "    driver.get(base_url)\n",
    "    num_of_pages = 1\n",
    "\n",
    "    # try click on \"דפים נוספים\" if available and extract the total number of pages to scan\n",
    "    try:\n",
    "        more_pages_button = driver.find_element(By.XPATH, \"/html/body/div[1]/div[1]/div[3]/div[1]/div[4]/div[1]/div[2]/div/ul[2]/li/a\")\n",
    "        more_pages_button.click()\n",
    "\n",
    "        # get the count of all button elements in the wrapper\n",
    "        all_pages_buttons_wrapper = driver.find_element(By.CLASS_NAME, \"pagination\")\n",
    "        all_pages_buttons = all_pages_buttons_wrapper.find_elements(By.TAG_NAME, \"li\")\n",
    "        num_of_pages = len(all_pages_buttons)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    for page in range(1, num_of_pages + 1):\n",
    "        current_url = base_url + f\"&page={page}\" \n",
    "        Extract_All_Sub_Categories_URLS_From_Letter_Page(current_url)\n",
    "\n",
    "# Loop_All_Letter_Page(\"https://www.midrag.co.il/Content/LttrInSec/1?lttr=%D7%94&lttrAsc=228\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main loop: read and update csv files\n",
    "def Scrap_from_categories_CSV():\n",
    "    CSV_name = \"all_categories.csv\"\n",
    "    df = pd.read_csv(f\"data/{CSV_name}\")\n",
    "    df_to_scan = df.loc[(df[\"Is Relevant\"] == 1) & (df[\"Scanned\"] == 0)]\n",
    "\n",
    "    for row in df_to_scan.itertuples(index=True):\n",
    "        print(row)\n",
    "        Get_All_Subcategories_By_URL(row.URL)\n",
    "        df.iloc[row.Index, 4] = 1\n",
    "        Save_CSV(CSV_name, df)\n",
    "\n",
    "    CSV_name = \"letters_URLs.csv\"\n",
    "    df = pd.read_csv(f\"data/{CSV_name}\")\n",
    "    df_to_scan = df.loc[df[\"Scanned\"] == 0]\n",
    "\n",
    "    for row in df_to_scan.itertuples(index=True):\n",
    "        Loop_All_Letter_Page(row.URL)\n",
    "        df.iloc[row.Index, 1] = 1\n",
    "        Save_CSV(CSV_name, df)\n",
    "   \n",
    "# Scrap_from_categories_CSV()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1bcf6aa5089fc5c5898a08ac643fd6d5eb64a5e1b049103d6b5e195c1f1aa1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
