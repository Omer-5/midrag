{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from os import path\n",
    "import warnings\n",
    "import folium\n",
    "from utils import Save_CSV, Append_Or_Create_CSV_By_Name\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract All Reviews from URL\n",
    "def Get_Reviews_Data_From_URL(url, filename):\n",
    "    \n",
    "    # XPath Elements\n",
    "    total_reivews_xpath = \"\"\"//*[@id=\"fullIntro\"]/span[1]\"\"\"\n",
    "    # category_title_xpath = \"\"\"//*[@id=\"layout-content-container\"]/div[1]/div[1]/div/ol/li[2]/a/span\"\"\"\n",
    "    category_title_xpath = \"\"\" /html/body/div[1]/div[1]/div[3]/div[1]/div[1]/ol/li[2]/a/span \"\"\"\n",
    "    \n",
    "    subcategory_title_xpath = \"\"\"//*[@id=\"feedbacks-index-container\"]/div[1]/h1\"\"\"\n",
    "    review_client_fullname_xpath = \"\"\"//*[@id=\"rank-{}\"]/div/div[1]/span[1]\"\"\"\n",
    "    # TODO: fix client name\n",
    "    review_location_xpath = \"\"\"//*[@id=\"rank-{}\"]/div/div[1]/span[1]/a\"\"\"\n",
    "    # TODO: fix location\n",
    "    review_date_xpath = \"\"\"//*[@id=\"rank-{}\"]/div/div[1]/span[3]\"\"\"\n",
    "    review_service_description_xpath = \"\"\"//*[@id=\"rank-{}\"]/div/div[1]/p\"\"\"\n",
    "    review_client_feedback_xpath = \"\"\"//*[@id=\"rank-{}\"]/div/div[2]/p\"\"\"\n",
    "    review_feedback_general_score_xpath = \"\"\"//*[@id=\"rank-{}\"]/div/div[3]/div/div/div[1]/div\"\"\"\n",
    "    review_feedback_quality_score_xpath = \"\"\"//*[@id=\"rank-{}\"]/div/div[3]/div/div/div[2]/div\"\"\"\n",
    "    review_feedback_price_score_xpath = \"\"\"//*[@id=\"rank-{}\"]/div/div[3]/div/div/div[3]/div\"\"\"\n",
    "    review_feedback_time_score_xpath = \"\"\"//*[@id=\"rank-{}\"]/div/div[3]/div/div/div[4]/div\"\"\"\n",
    "    review_feedback_treatment_score_xpath = \"\"\"//*[@id=\"rank-{}\"]/div/div[3]/div/div/div[5]/div\"\"\"\n",
    "    professional_total_reviews_xpath = \"\"\"//*[@id=\"feedbacks-section-container\"]/div[{}]/div[2]/div/div[2]/div[2]\"\"\"\n",
    "    professional_sysid_xpath = \"\"\"//*[@id=\"feedbacks-section-container\"]/div[{}]/div[1]/a\"\"\"\n",
    "    professional_image_xpath = \"\"\"//*[@id=\"feedbacks-section-container\"]/div[{}]/div[1]/span/img\"\"\"\n",
    "    professional_average_score_xpath = \"\"\"//*[@id=\"feedbacks-section-container\"]/div[{}]/div[2]/div/div[1]/div[2]\"\"\"\n",
    "    # \n",
    "\n",
    "    # Initiate Parameters & Webrowser\n",
    "    driver.get(url)\n",
    "    page_max = int(int(driver.find_element(By.XPATH, total_reivews_xpath).text)/10) + 1 # Reminder: 10 Reviews per Page --> For ex. 115 reviews means we need to iterate through(115/10)+1 pages\n",
    "    category_title = driver.find_element(By.XPATH, category_title_xpath).text\n",
    "    subcategory_title = driver.find_element(By.XPATH, subcategory_title_xpath).text\n",
    "    #\n",
    "\n",
    "    # Initiate DataFrames\n",
    "    # if(path.exists(filename)):\n",
    "    #     df_reviews = pd.read_csv(filename)\n",
    "    # else:\n",
    "    df_reviews = pd.DataFrame(columns=['Date', 'Category', 'Subcategory', 'Customer Name', 'Location', 'Service Categories', 'Review', 'Overall Score', 'Quality Score', 'Price Score', 'Time Score', 'Treatment Score', 'Professional SysID', 'Is Active', 'Total Prof. Reviews', 'Avg. Score'])\n",
    "    #\n",
    "    for page in range(1,page_max+1): # Iterate each page from 1-(page_max+1) --> collecting data and appending it to the main DataFrame\n",
    "        curr_url = url + '?page=' + str(page)\n",
    "        driver.get(curr_url)\n",
    "        \n",
    "        for i in range(1, 11): # Iterate each review\n",
    "            try: # Getting Review's Data from page\n",
    "\n",
    "                # Sometimes the customer name will apears as \"D.V. Tel-Aviv\" instead of \"Daniel Ventura, Tel-Aviv\" --> First 'if' checks if after splitting it with ',' the value stays the same meaning it doesn't have ',' in it.\n",
    "                # TODO: fix client name and location\n",
    "                if(driver.find_element(By.XPATH, review_client_fullname_xpath.format(i)).text[:-1].split(',')[0] == driver.find_element(By.XPATH, review_client_fullname_xpath.format(i)).text[:-1] ):\n",
    "                    client_fullname = str(driver.find_element(By.XPATH, review_client_fullname_xpath.format(i)).text[:-1].rsplit('.', 1)[0])\n",
    "                    location = str(driver.find_element(By.XPATH, review_client_fullname_xpath.format(i)).text[:-1].split('.')[-1].strip())\n",
    "                else:\n",
    "                    client_fullname = str(driver.find_element(By.XPATH, review_client_fullname_xpath.format(i)).text[:-1].split(',')[-2])\n",
    "                    location = str(driver.find_element(By.XPATH, review_client_fullname_xpath.format(i)).text[:-1].split(',')[-1].strip())\n",
    "\n",
    "                date = driver.find_element(By.XPATH, review_date_xpath.format(i)).text\n",
    "                service_description = driver.find_element(By.XPATH, review_service_description_xpath.format(i)).text\n",
    "                client_feedback = driver.find_element(By.XPATH, review_client_feedback_xpath.format(i)).text\n",
    "                feedback_general_score = driver.find_element(By.XPATH, review_feedback_general_score_xpath.format(i)).text\n",
    "                feedback_quality_score = driver.find_element(By.XPATH, review_feedback_quality_score_xpath.format(i)).text\n",
    "                feedback_price_score = driver.find_element(By.XPATH, review_feedback_price_score_xpath.format(i)).text\n",
    "                feedback_time_score = driver.find_element(By.XPATH, review_feedback_time_score_xpath.format(i)).text\n",
    "                feedback_treatment_score = driver.find_element(By.XPATH, review_feedback_treatment_score_xpath.format(i)).text\n",
    "                \n",
    "                professional_sysid = Extract_Professional_SysID(professional_sysid_xpath.format(i*2), professional_image_xpath.format(i*2))\n",
    "                professional_is_active = 1 if Is_Element_Exists(professional_sysid_xpath.format(i*2)) else 0\n",
    "                professional_total_reviews = driver.find_element(By.XPATH, professional_total_reviews_xpath.format(i*2)).text if (Is_Element_Exists(professional_total_reviews_xpath.format(i*2))) else 'לא ידוע'\n",
    "                professional_average_score = driver.find_element(By.XPATH, professional_average_score_xpath.format(i*2)).text if (Is_Element_Exists(professional_average_score_xpath.format(i*2))) else 'לא ידוע'\n",
    "                \n",
    "                df_reviews = df_reviews.append({'Date': date, 'Category': category_title, 'Subcategory': subcategory_title, 'Customer Name': client_fullname, 'Location': location, 'Service Categories': service_description, 'Review': client_feedback, 'Overall Score': feedback_general_score, 'Quality Score': feedback_quality_score, 'Price Score': feedback_price_score, 'Time Score': feedback_time_score, 'Treatment Score': feedback_treatment_score, 'Professional SysID': professional_sysid, 'Is Active': professional_is_active, 'Total Prof. Reviews': professional_total_reviews, 'Avg. Score': professional_average_score }, ignore_index=True)\n",
    "            \n",
    "            except Exception as e: \n",
    "                # print(i*page)\n",
    "                # print(e)\n",
    "                break # Exit the loop when can't find XPath element due to Exception --> meaning there is no other reviews left\n",
    "    \n",
    "    df_reviews['Date'] = pd.to_datetime(df_reviews['Date']) # Make sure the 'Date' column is in datetime object and not string\n",
    "    df_reviews.sort_values(by=['Category', 'Subcategory', 'Date'],inplace=True, ascending=[True, True, False])\n",
    "    # df_reviews.to_csv(filename, index=False, encoding = 'utf-8-sig') # Exports the reviews to csv file\n",
    "    Append_Or_Create_CSV_By_Name(filename, df_reviews)\n",
    "\n",
    "# Extract Professional SysID from given XPath --> A [div] in the XPath increasing by '2' for each review, therefore: i*2 for each unique XPath. for ex. 1st Review: .../div[2]/.. , 2nd Review: ..../div[4]/... etc.\n",
    "def Extract_Professional_SysID(SysID_XPath, Image_XPath):\n",
    "    if(Is_Element_Exists(SysID_XPath)):\n",
    "        string = driver.find_element(By.XPATH, SysID_XPath).get_attribute('href')\n",
    "        match = re.search(r'\\/SpCard\\/Sp\\/(\\d+)\\?', string)\n",
    "\n",
    "        return str(match.group(1))\n",
    "\n",
    "    elif(Is_Element_Exists(Image_XPath)):\n",
    "        string = driver.find_element(By.XPATH, Image_XPath).get_attribute('data-src')\n",
    "        if(string.find(\"SP_no_pic\") != -1 ):\n",
    "            return \"לא ידוע\"\n",
    "        else:\n",
    "            match = re.search(r'\\/Sp\\/(\\d+)\\.jpg', string)\n",
    "            return str(match.group(1))\n",
    "\n",
    "    return \"לא ידוע\"\n",
    "\n",
    "\n",
    "def Is_Element_Exists(XPath):\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, XPath)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "url = \"https://www.midrag.co.il/Content/FeedbacksIndex/570283\"\n",
    "filename = \"data\\\\reviews.csv\"\n",
    "# Get_Reviews_Data_From_URL(url, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Map that takes array of [locations, total_reviews] as an input, gets the Geo-Location of each location (using OpenStreeMap API) and Pin-Points the Top-5 Locations with the most reviews\n",
    "\n",
    "import requests\n",
    "\n",
    "map = folium.Map(location=[31.786060, 35.200779], zoom_start=7)\n",
    "\n",
    "df = pd.read_csv(\"data\\\\reviews.csv\")\n",
    "\n",
    "df['Location'] = df['Location'].astype(str)\n",
    "df['Location'] = df['Location'][~df['Location'].str.contains(r'\\d')]\n",
    "places = df['Location'].value_counts().to_dict()\n",
    "\n",
    "places_dict = []\n",
    "for location, total_reviews in places.items():\n",
    "    places_dict.append({'name': location, 'total_reviews': total_reviews})\n",
    "\n",
    "places_dict= sorted(places_dict, key=lambda x: x['total_reviews'], reverse=True)\n",
    "\n",
    "for place in places_dict[:5]:\n",
    "    popup = folium.Popup(f'<center><font size=\"2\"><b>{place[\"name\"]}</b></font><br><u>ביקורות</u>: {place[\"total_reviews\"]}', max_width=300)\n",
    "\n",
    "    url = f'https://nominatim.openstreetmap.org/search?q={place[\"name\"]}+Israel&format=json'\n",
    "    response = requests.get(url).json()\n",
    "    if response:\n",
    "        lat = response[0]['lat']\n",
    "        lon = response[0]['lon']\n",
    "\n",
    "    folium.Marker(location=[lat, lon], popup=popup).add_to(map)\n",
    "\n",
    "# map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Population of each Town in Israel (after getting the Geo-Location of them)\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "df_towns = pd.read_csv(\"data\\\\israel_towns.csv\")\n",
    "\n",
    "\n",
    "map = folium.Map(location=[31.786060, 35.200779], zoom_start=7)\n",
    "\n",
    "for index, row in df_towns.iterrows():\n",
    "    if( pd.notnull(row['Geo_lat']) & pd.notnull(row['Geo_lon']) ):\n",
    "        popup = folium.Popup(f'<center><font size=\"2\"><b>{row[\"Name\"]}</b></font><br><u>תושבים:</u>: {row[\"Population\"]}', max_width=300)\n",
    "\n",
    "        folium.Marker(location=[row[\"Geo_lat\"], row[\"Geo_lon\"]], popup=popup).add_to(map)\n",
    "\n",
    "# map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split all_subcateogries file into two\n",
    "\n",
    "df = pd.read_csv(\"data\\\\all_subcategories_URLs.csv\")\n",
    "\n",
    "df1 = df.iloc[:int(len(df)*0.5)]\n",
    "df2 = df.iloc[int(len(df)*0.5):]\n",
    "\n",
    "Save_CSV(\"all_subcategories_1.csv\", df1)\n",
    "Save_CSV(\"all_subcategories_2.csv\", df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel Ventura\\AppData\\Local\\Temp\\ipykernel_20676\\2530764259.py:78: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_reviews['Date'] = pd.to_datetime(df_reviews['Date']) # Make sure the 'Date' column is in datetime object and not string\n",
      "C:\\Users\\Daniel Ventura\\AppData\\Local\\Temp\\ipykernel_20676\\2530764259.py:78: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_reviews['Date'] = pd.to_datetime(df_reviews['Date']) # Make sure the 'Date' column is in datetime object and not string\n",
      "C:\\Users\\Daniel Ventura\\AppData\\Local\\Temp\\ipykernel_20676\\2530764259.py:78: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_reviews['Date'] = pd.to_datetime(df_reviews['Date']) # Make sure the 'Date' column is in datetime object and not string\n",
      "C:\\Users\\Daniel Ventura\\AppData\\Local\\Temp\\ipykernel_20676\\2530764259.py:78: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_reviews['Date'] = pd.to_datetime(df_reviews['Date']) # Make sure the 'Date' column is in datetime object and not string\n",
      "C:\\Users\\Daniel Ventura\\AppData\\Local\\Temp\\ipykernel_20676\\2530764259.py:78: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_reviews['Date'] = pd.to_datetime(df_reviews['Date']) # Make sure the 'Date' column is in datetime object and not string\n",
      "C:\\Users\\Daniel Ventura\\AppData\\Local\\Temp\\ipykernel_20676\\2530764259.py:78: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_reviews['Date'] = pd.to_datetime(df_reviews['Date']) # Make sure the 'Date' column is in datetime object and not string\n",
      "C:\\Users\\Daniel Ventura\\AppData\\Local\\Temp\\ipykernel_20676\\2530764259.py:78: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_reviews['Date'] = pd.to_datetime(df_reviews['Date']) # Make sure the 'Date' column is in datetime object and not string\n",
      "C:\\Users\\Daniel Ventura\\AppData\\Local\\Temp\\ipykernel_20676\\2530764259.py:78: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_reviews['Date'] = pd.to_datetime(df_reviews['Date']) # Make sure the 'Date' column is in datetime object and not string\n",
      "C:\\Users\\Daniel Ventura\\AppData\\Local\\Temp\\ipykernel_20676\\2530764259.py:78: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_reviews['Date'] = pd.to_datetime(df_reviews['Date']) # Make sure the 'Date' column is in datetime object and not string\n",
      "C:\\Users\\Daniel Ventura\\AppData\\Local\\Temp\\ipykernel_20676\\2530764259.py:78: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_reviews['Date'] = pd.to_datetime(df_reviews['Date']) # Make sure the 'Date' column is in datetime object and not string\n",
      "C:\\Users\\Daniel Ventura\\AppData\\Local\\Temp\\ipykernel_20676\\2530764259.py:78: UserWarning: Parsing dates in DD/MM/YYYY format when dayfirst=False (the default) was specified. This may lead to inconsistently parsed dates! Specify a format to ensure consistent parsing.\n",
      "  df_reviews['Date'] = pd.to_datetime(df_reviews['Date']) # Make sure the 'Date' column is in datetime object and not string\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m         df\u001b[39m.\u001b[39miloc[row\u001b[39m.\u001b[39mIndex, \u001b[39m4\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      9\u001b[0m         Save_CSV(CSV_name, df)\n\u001b[1;32m---> 10\u001b[0m Main_Crawler_Loop()\n",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m, in \u001b[0;36mMain_Crawler_Loop\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m df_to_scan \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[df[\u001b[39m\"\u001b[39m\u001b[39mScanned\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m df_to_scan\u001b[39m.\u001b[39mitertuples(index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m----> 7\u001b[0m     Get_Reviews_Data_From_URL(row\u001b[39m.\u001b[39;49mLink, \u001b[39m\"\u001b[39;49m\u001b[39mreviews_part_2.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m     df\u001b[39m.\u001b[39miloc[row\u001b[39m.\u001b[39mIndex, \u001b[39m4\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      9\u001b[0m     Save_CSV(CSV_name, df)\n",
      "Cell \u001b[1;32mIn[6], line 43\u001b[0m, in \u001b[0;36mGet_Reviews_Data_From_URL\u001b[1;34m(url, filename)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,page_max\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m): \u001b[39m# Iterate each page from 1-(page_max+1) --> collecting data and appending it to the main DataFrame\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     curr_url \u001b[39m=\u001b[39m url \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m?page=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(page)\n\u001b[1;32m---> 43\u001b[0m     driver\u001b[39m.\u001b[39;49mget(curr_url)\n\u001b[0;32m     45\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m11\u001b[39m): \u001b[39m# Iterate each review\u001b[39;00m\n\u001b[0;32m     46\u001b[0m         \u001b[39mtry\u001b[39;00m: \u001b[39m# Getting Review's Data from page\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \n\u001b[0;32m     48\u001b[0m             \u001b[39m# Sometimes the customer name will apears as \"D.V. Tel-Aviv\" instead of \"Daniel Ventura, Tel-Aviv\" --> First 'if' checks if after splitting it with ',' the value stays the same meaning it doesn't have ',' in it.\u001b[39;00m\n\u001b[0;32m     49\u001b[0m             \u001b[39m# TODO: fix client name and location\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel Ventura\\Documents\\GitHub\\midrag\\venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:455\u001b[0m, in \u001b[0;36mWebDriver.get\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    452\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[39m    Loads a web page in the current browser session.\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(Command\u001b[39m.\u001b[39;49mGET, {\u001b[39m\"\u001b[39;49m\u001b[39murl\u001b[39;49m\u001b[39m\"\u001b[39;49m: url})\n",
      "File \u001b[1;32mc:\\Users\\Daniel Ventura\\Documents\\GitHub\\midrag\\venv\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:442\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m    440\u001b[0m         params[\u001b[39m\"\u001b[39m\u001b[39msessionId\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msession_id\n\u001b[1;32m--> 442\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcommand_executor\u001b[39m.\u001b[39;49mexecute(driver_command, params)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m response:\n\u001b[0;32m    444\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_handler\u001b[39m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\Daniel Ventura\\Documents\\GitHub\\midrag\\venv\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:294\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    292\u001b[0m data \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39mdump_json(params)\n\u001b[0;32m    293\u001b[0m url \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url\u001b[39m}\u001b[39;00m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 294\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(command_info[\u001b[39m0\u001b[39;49m], url, body\u001b[39m=\u001b[39;49mdata)\n",
      "File \u001b[1;32mc:\\Users\\Daniel Ventura\\Documents\\GitHub\\midrag\\venv\\lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:316\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    313\u001b[0m     body \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    315\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 316\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conn\u001b[39m.\u001b[39;49mrequest(method, url, body\u001b[39m=\u001b[39;49mbody, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[0;32m    317\u001b[0m     statuscode \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus\n\u001b[0;32m    318\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Daniel Ventura\\Documents\\GitHub\\midrag\\venv\\lib\\site-packages\\urllib3\\request.py:78\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_url(\n\u001b[0;32m     75\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[0;32m     76\u001b[0m     )\n\u001b[0;32m     77\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_encode_body(\n\u001b[0;32m     79\u001b[0m         method, url, fields\u001b[39m=\u001b[39mfields, headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39murlopen_kw\n\u001b[0;32m     80\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Daniel Ventura\\Documents\\GitHub\\midrag\\venv\\lib\\site-packages\\urllib3\\request.py:170\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    167\u001b[0m extra_kw[\u001b[39m\"\u001b[39m\u001b[39mheaders\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mupdate(headers)\n\u001b[0;32m    168\u001b[0m extra_kw\u001b[39m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 170\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kw)\n",
      "File \u001b[1;32mc:\\Users\\Daniel Ventura\\Documents\\GitHub\\midrag\\venv\\lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    375\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39murlopen(method, u\u001b[39m.\u001b[39mrequest_uri, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[39m=\u001b[39m redirect \u001b[39mand\u001b[39;00m response\u001b[39m.\u001b[39mget_redirect_location()\n\u001b[0;32m    379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\Daniel Ventura\\Documents\\GitHub\\midrag\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Daniel Ventura\\Documents\\GitHub\\midrag\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    444\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    451\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Daniel Ventura\\Documents\\GitHub\\midrag\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    441\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    443\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    449\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def Main_Crawler_Loop():\n",
    "    CSV_name = \"all_subcategories_URL.csv\"\n",
    "    df = pd.read_csv(f\"data/{CSV_name}\") \n",
    "    df_to_scan = df.loc[df[\"Scanned\"] == 0]\n",
    "\n",
    "    for row in df_to_scan.itertuples(index=True):\n",
    "        Get_Reviews_Data_From_URL(row.Link, \"testing.csv\")\n",
    "        df.iloc[row.Index, 4] = 1\n",
    "        Save_CSV(CSV_name, df)\n",
    "        break\n",
    "Main_Crawler_Loop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ab1ab09545bee650d721a7b049b9ed441d6bb9817cd90b7bdfc0883f5dc7f15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
